{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student number/Studentenommer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions**: Answer the following questions **in the answer book provided**, doing calculations in this notebook where necessary/desired.  Submit the notebook on SunLearn, and hand in the answer book.\n",
    "Give answers accurate to 3 decimal places in the answer book.\n",
    "\n",
    "**Complete your student number above.**\n",
    "\n",
    "---------\n",
    "**Instruksies**: *Beantwoord die volgende vrae **in die antwoordboek wat verskaf is**, en doen u berekeninge in hierdie notaboek waar nodig/gewens.  Dien hierdie notaboek op SunLearn in, en handig die antwoordboek in.\n",
    "Gee antwoorde in die antwoordboek akkuraat tot 3 desimale plekke. *\n",
    "\n",
    "** *Voltooi u studentenommer hierbo.* **\n",
    "\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1 (7 marks).** Consider the matrix $M$ representing four 2-dimensional observations below. // ** *Vraag 1 (7 punte).* ** *Beskou die matriks $M$, wat vier 2-dimensionele waarnemings voorstel, hieronder.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.array([[2, 4], [1, 3], [0, 0], [0, 0]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Calculate $M_c$, the matrix of centred observations.[1] // *Bereken $M_c$, die matriks van gesentreerde waarnemings.*[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.  1.]\n",
      " [-1.  1.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(M,axis=1)[:,np.newaxis]\n",
    "Mc=M-mean\n",
    "print(Mc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Give the SVD of $M_c$. [1] // *Gee die SVD van $M_c$.* [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, s, vh = np.linalg.svd(Mc,full_matrices=False) #U, S(covariance matrix), Vtransposed\\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Give (i) the sample covariance matrix for the data matrix $M$ [2] and (ii) its eigenvalues [1].  (Divide by $N$, not by $N-1$, in the formula for the sample covariance matrix). // *Gee (i) die steekproefkovariansiematriks vir die datamatriks $M$ [2] en (ii) sy eiewaardes [1].  (Deel deur $N$, nie $N-1$ nie, in die formule vir die steekproefkovariansiematriks.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.25 0.25]\n",
      " [0.25 0.25]]\n"
     ]
    }
   ],
   "source": [
    "m,n=Mc.shape\n",
    "N=m*n#all the values of N\n",
    "sigma=np.diag(s)\n",
    "S=(1/N)*(vh.dot(sigma*sigma).dot(vh.T))\n",
    "print(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Let $\\sigma_i$ be the $i$-th largest singular value of the centred version of a data matrix with $N$ observations and $\\lambda_i$ the $i$-th largest eigenvalue of the corresponding covariance matrix. (i) Give a formula relating $\\sigma_i$ and $\\lambda_i$. [1] (ii) Write down numerical expressions verifying this relationship in the case of the matrix $M$ above. //  *Laat $\\sigma_i$ die $i$-de grootste singuliere waarde wees van die gesentreerde weergawe van 'n datamatriks met $N$ waarnemings, en $\\lambda_i$ die $i$-de grootste eiewaarde van die ooreenstemmende kovariansiematriks. (i) Gee 'n formule met 'n verwantskap tussen $\\sigma_i$ en $\\lambda_i$. [1] (ii) Skryf neer numeriese uitdrukkings om hierdie verwantskap te verifieer in die geval van die matriks $M$ hierbo. [1]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4142135623730951\n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "sigma_i=np.sqrt(S[0,0]*N)\n",
    "print(sigma_i)\n",
    "\n",
    "print(sigma[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2 (2 marks).** The code below should load the data matrix from the Boston House Prices benchmark data set into the variable `boston`. // ** *Vraag 2 (2 punte).* ** *Die kode hieronder behoort die datamatriks van die Boston Huispryse maatstafdatastel in die veranderlike `boston` te laai.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston().data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) How many of the PCA features explain at least 0.1% of the variance in this data set? [1] // *Hoeveel van die HKA kenmerkvektore verklaar ten minste 0.1% van die variansie in hierdie datastel? [1]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) What is the vector of scores for each feature associated with the first point in the data set when using this number of principal components? [1] // *Wat is die vektor van tellings vir elke kenmerkvektor geassosieer met die eerste punt in die datastel as mens hierdie aantal hoofkomponente gebruik? [1]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3 (1 mark).** An important step in implementing linear discriminant analysis is performing PCA on the average\n",
    "within-class covariance matrix.  Explain what is wrong with the following code snippet to calculate this matrix: // ** *Vraag 3 (1 punt).* ** *'n Belangrike stap in die implementasie van lineêre diskriminantanalise is HKA uitvoer op die gemiddelde binneklaskovariansiematriks.  Verduidelik wat fout is met die volgende stuk kode om hierdie matriks te bereken:*"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# aveclasscov - desired matrix / gesoekte matriks\n",
    "# d - dimension of observations / dimensie van waarnemings\n",
    "# classes - list of classes / lys van klasse\n",
    "# data - data matrix / datamatriks\n",
    "# labels - list of class membership for each observation / lys van klaslidmaatskap vir elke waarneming\n",
    "# numclasses - number of classes / aantal klasse\n",
    "\n",
    "aveclasscov = np.zeros(d, d)\n",
    "for c in classes:\n",
    "    submatrix = data[:, labels == c]\n",
    "    aveclasscov += np.cov(submatrix, bias=1)\n",
    "aveclasscov /= numclasses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4 (1 mark).** Suppose you have a training data set from an investment company with 174 metrics per client (capturing information about investment behaviour, spending patterns, demographics, etc.), and a classification for each client into the categories paranoid, risk-averse, risk-tolerant, risk-seeking, or maverick.  You decide to pre-process the data using linear discriminant analysis for dimensionality reduction. // ** *Vraag 4 (1 punt).* ** *Veronderstel u het 'n afrigdatastel van 'n beleggingsmaatskappy met 174 statistieke per kliënt (wat inligting bevat oor beleggingsgedrag, spanderingspatrone, demografie, ens.), asook 'n etiket vir elke kliënt uit die kategorieë paranoïes, risiko-vermydend, risiko-aanvarend, risiko-soekend, en waaghalsig.  U besluit om die data te voorverwerk met lineêre diskriminant analise vir dimensionaliteitsvermindering.*\n",
    "\n",
    "How many (meaningful) dimensions will your transformed data have (at most) when you have completed this pre-processing? [1] // *Hoeveel (betekenisvolle) dimensies sal u getransformeerde data (hoogstens) hê wanneer u die voorverwerking voltooi het? [1]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5 (1 mark).** Apply linear discriminant analysis to the (full) Fisher Iris data set, loaded below.  Then give the proportion of within-class variance explained by the first principal component used in the whitening transform. // ** *Vraag 5 (1 punt)* ** *Pas lineêre diskriminant analise toe op die (volle) Fisher Iris data stel, wat hieronder gelaai word.  Gee dan die proporsie van binneklas variansie verklaar deur die eerste hoofkomponent gebruik in die  verwittingstransformasie.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris_data = load_iris()\n",
    "X = iris_data.data # observations\n",
    "y = iris_data.target # labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
