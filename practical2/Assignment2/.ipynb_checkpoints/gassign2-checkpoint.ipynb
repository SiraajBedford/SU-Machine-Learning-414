{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB: Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'jupyterthemes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-bbf634a2de24>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mjupyterthemes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjtplot\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[0mjtplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheme\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'monokai'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'notebook'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mticks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'jupyterthemes'"
     ]
    }
   ],
   "source": [
    "# Import different modules for using with the notebook\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cee_em\n",
    "from IPython.display import HTML\n",
    "from IPython.display import display\n",
    "from IPython.display import Image\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression as logis\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# -------------------------------\n",
    "#    Manual Prep\n",
    "# -------------------------------\n",
    "\n",
    "from sklearn import linear_model, datasets\n",
    "import itertools\n",
    "from matplotlib.colors import ListedColormap\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# from jupyterthemes import jtplot\n",
    "# jtplot.style(theme='monokai', context='notebook', ticks=True, grid=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix Plotter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=True,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data - three randomly-generated Gaussian-distributed \n",
    "# clouds of points in 2d space\n",
    "np.random.seed(0)\n",
    "# Number of points\n",
    "N = 1000\n",
    "# Labels for each cluster\n",
    "y = np.random.randint(low=0, high=2+1, size = N)\n",
    "# Mean of each cluster\n",
    "means = np.array([[-1, 1, -1], [-1, 1, 1],])\n",
    "# Covariance (in X and Y direction) of each cluster\n",
    "covariances = np.random.random_sample((2, 3)) + 1\n",
    "# Dimensions of each point\n",
    "X = np.vstack([np.random.randn(N)*covariances[0, y] + means[0, y],\n",
    "               np.random.randn(N)*covariances[1, y] + means[1, y]])\n",
    "X = X.T\n",
    "\n",
    "print(y.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the data that you generated to find something like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(Image(filename='./images/wm_dat1.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#--------------------------------------------------------\n",
    "#                Your Work Here\n",
    "#--------------------------------------------------------\n",
    "c = np.array([\"r\",\"g\",\"b\"])\n",
    "\n",
    "for k in range(X.T.shape[1]):\n",
    "    plt.plot(X.T[0,k],X.T[1,k],c[y[k]]+\"o\")\n",
    "    \n",
    "plt.xlabel(\"$x_1$\")\n",
    "plt.ylabel(\"$x_2$\")\n",
    "plt.title(\"Three Classes: Two Features\")\n",
    "plt.show()\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the training data to the scikit-learn softmax classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------\n",
    "#                Your Work Here\n",
    "#--------------------------------------------------------\n",
    "\n",
    "clf = logis(C=1e5)\n",
    "clf.fit(X, y)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image above shows that there is considerable overlap between the classes. \n",
    "\n",
    "**Use your trained classifier to assign all the training data to different classes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------\n",
    "#                Your Work Here\n",
    "#--------------------------------------------------------\n",
    "\n",
    "y_predict = clf.predict(X)\n",
    "\n",
    "print(y_predict.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print the confusion matrix and also plot it, to get something like the image below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(Image(filename='./images/wm_confusion.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------\n",
    "#                Your Work Here\n",
    "#--------------------------------------------------------\n",
    "\n",
    "\n",
    "c = np.array([\"r\",\"g\"]) # use [\"r\", \"g\", \"b\"] for 3 classes\n",
    "cm = confusion_matrix(y,y_predict)\n",
    "plot_confusion_matrix(cm,c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the different classes as predicted by your system. You should get something like:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(Image(filename='./images/wm_dat2.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------\n",
    "#                Your Work Here\n",
    "#--------------------------------------------------------\n",
    "\n",
    "# SETUP\n",
    "h = 0.02\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# COLORMESH PLOT\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure()\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "# SCATTER PLOT\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_predict, cmap=cmap_bold,\n",
    "          edgecolor='k', s=20)\n",
    "plt.axis('tight')\n",
    "\n",
    "# SHAPE TEST -- FOR DEBUGGING PURPOSES ONLY\n",
    "print(X.shape)\n",
    "print(y_predict.shape)\n",
    "print(xx.shape)\n",
    "print(yy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Can you tell from the graph that this is a *linear* classifier?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER: YES. Especially from the colormesh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement a Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implement your own Naive Bayes Classifier** (from first principles). Train it using the exact same data you used for the previous question (write it in a seperate python file which you can import into the notebook). Implement it in a generic way, i.e. it should be able to work on $d$ dimensional data and it should not be limited to a certain amount of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------\n",
    "#                Your Work Here\n",
    "#--------------------------------------------------------\n",
    "\n",
    "from gstuff import NaiveClassifier as naive\n",
    "\n",
    "clf = naive.NaiveClassifier()\n",
    "clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use your trained classifier to assign all the training data to different classes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------\n",
    "#                Your Work Here\n",
    "#--------------------------------------------------------\n",
    "\n",
    "y_predict = clf.predict(X)\n",
    "\n",
    "print(\"variances:\")\n",
    "print(clf.get_variances())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print the confusion matrix and also plot it, to get something like the image below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(Image(filename='./images/conf_mat_bayes.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------\n",
    "#                Your Work Here\n",
    "#--------------------------------------------------------\n",
    "\n",
    "c = np.array([\"r\",\"g\"]) # use [\"r\", \"g\", \"b\"] for 3 classes\n",
    "cm = confusion_matrix(y,y_predict)\n",
    "plot_confusion_matrix(cm,c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the different classes as predicted by your system. You should get something like:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(Image(filename='./images/predict_bayes.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------\n",
    "#                Your Work Here\n",
    "#--------------------------------------------------------\n",
    "\n",
    "# SETUP\n",
    "h = 0.02\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# COLORMESH PLOT --- TAKES SUPER LONG WITH MY CODE\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure()\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "# SCATTER PLOT\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_predict, cmap=cmap_bold,\n",
    "          edgecolor='k', s=20)\n",
    "plt.axis('tight')\n",
    "\n",
    "# SHAPE TEST -- FOR DEBUGGING PURPOSES ONLY\n",
    "print(X.shape)\n",
    "print(y_predict.shape)\n",
    "print(xx.shape)\n",
    "print(yy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement a Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use the following data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data - two randomly-generated Gaussian-distributed clouds of points in 2d space\n",
    "np.random.seed(0)\n",
    "# Number of points\n",
    "N = 1000\n",
    "# Labels for each cluster\n",
    "y = np.random.randint(low=0, high=2, size = N)\n",
    "# Mean of each cluster\n",
    "means = np.array([[-1, 1], [-1, 1],])\n",
    "# Covariance (in X and Y direction) of each cluster\n",
    "covariances = np.random.random_sample((2, 2)) + 1\n",
    "# Dimensions of each point\n",
    "X = np.vstack([np.random.randn(N)*covariances[0, y] + means[0, y],\n",
    "               np.random.randn(N)*covariances[1, y] + means[1, y]])\n",
    "\n",
    "X = X.T # converts the data to row data, like all the other data\n",
    "\n",
    "print(y.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implement your own Logistic Regression classifier for two classes only** (from first principles). It should be generic and be able to work on $d$ dimensional data (and two classes). Please make your implementation as modular as possible, having a seperate function for the Hessian and the gradient vector (write it in a seperate python file which you can import into the notebook). A regularization term based on a Gaussian prior (with zero mean and covariance matrix $\\lambda\\mathbf{I}$) must be included.  Optionally, a bias term also needs to be incorporated into your classifier - this can be implemented by augmenting the training dataset with an additional all-one feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------\n",
    "#                Your Work Here\n",
    "#--------------------------------------------------------\n",
    "\n",
    "from gstuff import LogisticRegression as logreg\n",
    "\n",
    "hyper = 2\n",
    "tolerance = 1e-5\n",
    "clf = logreg.LogisticRegression(hyper, tolerance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use your classifier to fit the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------\n",
    "#                Your Work Here\n",
    "#--------------------------------------------------------\n",
    "\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use your trained classifier to assign all the training data to different classes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------\n",
    "#                Your Work Here\n",
    "#--------------------------------------------------------\n",
    "\n",
    "y_predict = clf.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print the confusion matrix and also plot it, to get something like the image below:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(Image(filename='./images/conf_mat_logreg.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------\n",
    "#                Your Work Here\n",
    "#--------------------------------------------------------\n",
    "\n",
    "c = np.array([\"r\",\"g\"]) # use [\"r\", \"g\", \"b\"] for 3 classes\n",
    "cm = confusion_matrix(y,y_predict)\n",
    "plot_confusion_matrix(cm,c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the different classes as predicted by your system. Add your decision boundary to the same plot. You should get something like:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(Image(filename='./images/predict_logreg.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------\n",
    "#                Your Work Here\n",
    "#--------------------------------------------------------\n",
    "\n",
    "# SETUP\n",
    "h = 0.02\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# COLORMESH PLOT\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure()\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "# SCATTER PLOT\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_predict, cmap=cmap_bold,\n",
    "          edgecolor='k', s=20)\n",
    "plt.axis('tight')\n",
    "\n",
    "# SHAPE TEST -- FOR DEBUGGING PURPOSES ONLY\n",
    "print(X.shape)\n",
    "print(y_predict.shape)\n",
    "print(xx.shape)\n",
    "print(yy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Before continuing in the notebook, you will need to install the `lasagne` Python module with \"pip3 install --user lasagne\" **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify the MNIST digits \n",
    "\n",
    "First load the dataset - for more information about the dataset, see http://yann.lecun.com/exdb/mnist/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist import load_dataset\n",
    "X_train, y_train, X_valid, y_valid, X_test, y_test = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST database provided in the assignment resources consists of low-resolution (28x28) grayscale images of handwritten digits ($0,1,2,3,4,5,6,7,8,9$). First, you read in a set of training digits and display them interactively to get an idea what they look like. Afterwards, you build and train a softmax classifier using scitkit-image and scikit-learn. You will then classify the digits in the test set and display the results. Finally, you will display the weights as images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the test digits interactively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "def show_digits(n=0):\n",
    "    \"\"\"\n",
    "    Show the first 1000 digits in the training set\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.imshow(X_train[n][0], cmap=cee_em.binary)   \n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "#w = interact(show_digits, n =(0, 1000)) # JUPYTER HAS TRUST ISSUES WITH INTERACT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the softmax classifier\n",
    "\n",
    "**Use the training set to build a softmax classifier. Use this classifier to classify the digits in the training set and the test set separately. Print the confusion matrix and also display it as an image for each case to get something like:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(Image(filename='./images/wm_confusion2.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------\n",
    "#                Your Work Here\n",
    "#--------------------------------------------------------\n",
    "X = X_train[:,0].reshape(50000, -1)\n",
    "y = y_train\n",
    "\n",
    "clf = logis(C=1e5)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# TRAIN DATA PREDICTIONS\n",
    "#y_predict = clf.predict(X)\n",
    "\n",
    "#c = np.array([\"r\",\"g\"]) # use [\"r\", \"g\", \"b\"] for 3 classes\n",
    "#cm = confusion_matrix(y,y_predict)\n",
    "#plot_confusion_matrix(cm,c)\n",
    "\n",
    "print(X_test.shape)\n",
    "\n",
    "X = X_test[:,0].reshape(10000, -1)\n",
    "y = y_test\n",
    "\n",
    "# TEST DATA PREDICTIONS\n",
    "y_predict = clf.predict(X)\n",
    "\n",
    "c = np.array([\"r\",\"g\"]) # use [\"r\", \"g\", \"b\"] for 3 classes\n",
    "cm = confusion_matrix(y,y_predict)\n",
    "plot_confusion_matrix(cm,c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "\n",
    "**Calculate the accuracy of your system as a fraction of the correctly classified digits. You should get something like 0.9254. use - `logis(C=1e5, solver='lbfgs', multi_class='multinomial')`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------\n",
    "#                Your Work Here\n",
    "#--------------------------------------------------------\n",
    "\n",
    "clf = logis(C=1e5, solver='lbfgs', multi_class='multinomial')\n",
    "\n",
    "clf.fit(X, y)\n",
    "y_predict = clf.predict(X)\n",
    "\n",
    "c = np.array([\"r\",\"g\"]) # use [\"r\", \"g\", \"b\"] for 3 classes\n",
    "cm = confusion_matrix(y,y_predict)\n",
    "plot_confusion_matrix(cm,c)\n",
    "\n",
    "correct = 0\n",
    "\n",
    "for n in range(0, 10000):\n",
    "    if y[n] == y_predict[n]:\n",
    "        correct += 1\n",
    "    \n",
    "print(\"Accuracy:\")\n",
    "accuracy = correct/10000\n",
    "print(accuracy)\n",
    "\n",
    "accuracy = clf.score(X, y, sample_weight=None)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the weights and display as images.\n",
    "\n",
    "**Extract the weights of the softmax classifier and display them as images. Each set of weights should correspond to a specific digit**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As an example the weight image associated with the 0 digit should look similar to this:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(Image(filename='./wm_softmax_mnist_weights/wm_0.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------\n",
    "#                Your Work Here\n",
    "#--------------------------------------------------------\n",
    "\n",
    "# plot weights vs the pixel position\n",
    "coef = clf.coef_.copy()\n",
    "\n",
    "def show_weights(n=0):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    scale = np.abs(coef).max()\n",
    "\n",
    "    #l2_plot = plt.subplot(2, 5, n + 1)\n",
    "\n",
    "    \n",
    "    plt.imshow(coef[n].reshape(28, 28), interpolation='nearest',\n",
    "                   cmap='viridis', vmin=-scale, vmax=scale)   \n",
    "    \n",
    "#w = interact(show_weights, n = (0, 9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Further investigation\n",
    "\n",
    "Fit the softmax classifier for different values of the regularization parameter - we recommend values evenly spaced on the log scale - and show the corresponding weight images for some digit as the parameter changes.  Explain the changes in the weight images observed. Moreover, plot the accuracy of your classifier as a function of the regularization parameter. Use this plot to expand on your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------\n",
    "#                Your Work Here\n",
    "#--------------------------------------------------------\n",
    "accuracy = [0. for p in range(0, 10)]\n",
    "lambdaa = [0. for p in range(0, 10)]\n",
    "\n",
    "for p in range(0, 10):\n",
    "    X = X_train[:,0].reshape(50000, -1)\n",
    "    y = y_train\n",
    "    \n",
    "    lambdaa[p] = 1 * 10 ** p\n",
    "    clf = logis(C=lambdaa[p])\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    X = X_train[:,0].reshape(X_train.shape[0], -1)\n",
    "    y = y_train\n",
    "\n",
    "    y_predict = clf.predict(X)\n",
    "    \n",
    "    accuracy[p] = clf.score(X, y, sample_weight=None)\n",
    "\n",
    "for p in range(0, 10):\n",
    "    print(\"Accuracy for lamda {} is: {}\".format(lambdaa[p], accuracy[p]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It can be seen that Choosing C = 1 works much better than C = 1e5 ... "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
